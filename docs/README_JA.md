<div align="center">
  <img src="./images/logo.png" alt="VideoCaptioner ロゴ" width="100">
  <p>カカ字幕アシスタント</p>
  <h1>VideoCaptioner</h1>
  <p>大規模言語モデル(LLM)を基盤とした動画字幕処理アシスタント。音声認識、字幕の分割、最適化、翻訳までの全工程をサポート</p>

  [简体中文](../README.md) / [英語](./docs/README_EN.md) / 日本語

</div>

## 📖 プロジェクト概要

カカ字幕アシスタント（VideoCaptioner）は、操作が簡単で高性能なハードウェアを必要としないツールです。オンラインAPIとローカルGPU処理の両方に対応した音声認識機能を提供し、大規模言語モデルを活用して字幕の分割、校正、翻訳を行います。動画字幕の全工程をワンクリックで処理し、魅力的な字幕を作成できます。

最新バージョンでは、VAD（音声活性化検出）、ボイス分離、単語レベルのタイムスタンプなどの実用的な機能をサポートしています。

- 🎯 GPUなしでも高性能な音声認識エンジンを使用可能
- ✂️ LLMベースのスマートな分割と句読点付け
- 🔄 AIによるマルチスレッド字幕最適化と翻訳
- 🎬 バッチ処理による効率的な字幕合成
- 📝 直感的な字幕編集・プレビューインターフェース
- 🤖 低トークン消費と基本LLMモデル内蔵でスムーズな使用感

## 📸 インターフェースプレビュー

<div align="center">
  <img src="https://h1.appinn.me/file/1731487405884_main.png" alt="ソフトウェアインターフェースプレビュー" width="90%" style="border-radius: 5px;">
</div>

![ページプレビュー](https://h1.appinn.me/file/1731487410170_preview1.png)
![ページプレビュー](https://h1.appinn.me/file/1731487410832_preview2.png)

## 🧪 テスト結果

14分間の1080P [Bilibili英語TED動画](https://www.bilibili.com/video/BV1jT411X7Dz)を処理した場合、ローカルWhisperモデルで音声認識を行い、`gpt-4o-mini`モデルで最適化と中国語翻訳を実施。全工程の所要時間は約**4分**です。

バックエンド計算によると、モデルの最適化と翻訳にかかる費用は￥0.01未満（OpenAI公式価格基準）です。

字幕と動画合成の具体的な効果については、[TEDビデオテスト](./docs/test.md)をご参照ください。

## 🚀 クイックスタート

### Windowsユーザー

ソフトウェアは軽量で、パッケージサイズは60MB未満。必要な環境が全て同梱されているため、ダウンロード後すぐに実行できます。

1. [Release](https://github.com/WEIFENG2333/VideoCaptioner/releases)ページから最新版の実行ファイルをダウンロード。または[藍奏雲からダウンロード](https://wwwm.lanzoue.com/idzKZ2hjcimb)

2. インストールパッケージを開いてインストール

3. （任意）LLM API設定、字幕最適化や翻訳機能の有効化

4. 動画ファイルをソフトウェアウィンドウにドラッグ＆ドロップで自動処理開始

注：各ステップは個別に処理可能で、ファイルのドラッグ＆ドロップに対応しています。

<details>
<summary>MacOSユーザー</summary>

開発者がMacを所持していないため、テストやパッケージングができず、MacOS用の実行ファイルは現在提供できません。

MacユーザーはソースコードをダウンロードしてPython依存関係をインストールして実行してください（ローカルWhisper機能は現在MacOSをサポートしていません）。

1. ffmpegとAria2ダウンローダーをインストール
```bash
brew install ffmpeg
brew install aria2
```

2. プロジェクトをクローン
```bash
git clone https://github.com/WEIFENG2333/VideoCaptioner.git
```

3. 依存関係をインストール
```bash
pip install -r requirements.txt
```

4. プログラムを実行
```bash
python main.py
```
</details>

## ✨ 主要機能

本ソフトウェアは、大規模言語モデル（LLM）の文脈理解能力を最大限に活用し、音声認識で生成された字幕を更に処理します。誤字脱字を修正し、専門用語を統一することで、字幕の内容をより正確で一貫したものにし、視聴者により良い体験を提供します！

#### 1. マルチプラットフォーム動画ダウンロードと処理
- 国内外の主要動画プラットフォーム（Bilibili、Youtubeなど）に対応
- 動画の既存字幕を自動抽出して処理

#### 2. プロフェッショナルな音声認識エンジン
- 複数のオンラインAPI（無料、高速）を提供
- ローカルWhisperモデル対応（プライバシー保護、オフライン使用可能）

#### 3. 字幕のスマート修正
- 専門用語、コードスニペット、数式フォーマットの自動最適化
- 文脈を考慮した文章分割の最適化で読みやすさを向上
- 原稿やヒントを活用した字幕分割の最適化をサポート

#### 4. 高品質な字幕翻訳
- 文脈を考慮したスマート翻訳で全体の一貫性を確保
- Promptを使用してAIモデルの翻訳を改善
- シーケンスファジーマッチングアルゴリズムでタイムラインの完全一致を保証

#### 5. 字幕スタイル調整
- 豊富な字幕スタイルテンプレート（教育、ニュース、アニメスタイルなど）
- 複数の字幕フォーマット対応（SRT、ASS、VTT、TXT）

## ⚙️ 基本設定

### 1. LLM API設定説明（任意）

| 設定項目 | 説明 |
|--------|------|
| 内蔵モデル | ソフトウェアに基本的な大規模言語モデル（`gpt-4o-mini`）が内蔵されており、設定不要で使用可能 |
| API対応 | 標準OpenAI APIフォーマットをサポート。[SiliconCloud](https://cloud.siliconflow.cn/i/HF95kaoz)、[DeepSeek](https://platform.deepseek.com/)、[Ollama](https://ollama.com/blog/openai-compatibility)などと互換。<br>設定方法は[設定ドキュメント](./docs/llm_config.md)を参照 |

推奨モデル: より高品質を求める場合は`Claude-3.5-sonnet`または`gpt-4o`を選択

### 2. ローカルWhisper音声認識設定（ソフトウェア内でのダウンロードが必要）

WhisperにはWhisperCppとfasterWhisperの2つのバージョンがあり、後者の方が効果が高く、どちらもソフトウェア内でモデルをダウンロードする必要があります。

| モデル | ディスク容量 | メモリ使用量 | 説明 |
|------|----------|----------|------|
| Tiny | 75 MiB | ~273 MB | 変換品質は普通、テスト用 |
| Small | 466 MiB | ~852 MB | 英語認識は良好 |
| Medium | 1.5 GiB | ~2.1 GB | 中国語認識はこのバージョン以上を推奨 |
| Large-v1/v2 | 2.9 GiB | ~3.9 GB | 効果良好、リソースが許せば推奨 |
| Large-v3 | 2.9 GiB | ~3.9 GB | コミュニティからの報告では幻聴/字幕重複の可能性あり |

注：上記モデルは中国国内でもソフトウェア内で直接ダウンロード可能。GPUと統合グラフィックスの両方に対応。

### 3. 原稿マッチング

- 「字幕最適化と翻訳」ページには「原稿マッチング」オプションがあり、以下の**1つまたは複数**のコンテンツで字幕校正と翻訳をサポート:

| タイプ | 説明 | 記入例 |
|------|------|------|
| 用語集 | 専門用語、人名、特定の語句の修正対照表 | 機械学習->Machine Learning<br>マスク->Elon Musk<br>応援->打call<br>チューリングパターン<br>バス・パラドックス |
| 原稿 | 動画の原稿または関連コンテンツ | 完全なスピーチ原稿、講義資料など |
| 修正要件 | コンテンツに関する具体的な修正要件 | 人称代名詞の統一、専門用語の標準化など<br>**コンテンツに関連する**要件を記入、[例を参照](https://github.com/WEIFENG2333/VideoCaptioner/issues/59#issuecomment-2495849752) |

- 原稿を使用して字幕最適化を補助する場合、全工程処理時に先に原稿情報を入力してから処理を開始
- 注意: コンテキストパラメータの少ない小型LLMモデルを使用する場合、原稿内容を1000文字以内に抑えることを推奨。より大きなコンテキストを持つモデルを使用する場合は、適宜増やすことが可能。

### 4. 音声認識インターフェース説明

| インターフェース名 | 対応言語 | 実行方式 | 説明 |
|---------|---------|---------|------|
| Bインターフェース | 中国語、英語のみ | オンライン | 無料、比較的高速 |
| Jインターフェース | 中国語、英語のみ | オンライン | 無料、比較的高速 |
| WhisperCpp | 中国語、日本語、韓国語、英語など99言語、外国語の効果が良好 | ローカル | 変換モデルのダウンロードが必要<br>中国語はmedium以上推奨<br>英語などは小さいモデルでも良好な効果が得られる |
| fasterWhisper | 中国語、英語など99言語、外国語の効果優秀、タイムライン精度向上 | ローカル | プログラムと変換モデルのダウンロードが必要<br>CUDA対応で高速、変換精度が高い<br>優先使用を推奨 |

### 5. Cookie設定説明

URLダウンロード機能を使用する際、以下の状況に遭遇した場合:
1. ダウンロードする動画にログイン情報が必要
2. 低解像度の動画しかダウンロードできない
3. ネットワーク状態が悪い時に認証が必要

- [Cookie設定説明](./docs/get_cookies.md)を参照してCookie情報を取得し、cookies.txtファイルをソフトウェアの`AppData`ディレクトリに配置することで、高品質な動画を正常にダウンロードできます。

## 💡 ソフトウェアの処理フロー

プログラムの基本的な処理フローは以下の通り:
```
音声認識 -> 字幕分割 -> 字幕最適化翻訳(任意) -> 字幕動画合成
```

インストールしたソフトウェアの主要ディレクトリ構造は以下の通り：
```
VideoCaptioner/
├── runtime/                 # ランタイム環境ディレクトリ（変更不要）
├── resources/               # ソフトウェアリソースファイルディレクトリ（UI、アイコンなど、変更不要）
├── work-dir/                # 作業ディレクトリ、処理完了した動画と字幕ファイルが保存される
├── AppData/                 # アプリケーションデータディレクトリ
    ├── cache/               # キャッシュディレクトリ、一時データ
    ├── models/              # Whisperモデルファイル保存場所
    ├── logs/                # ログディレクトリ、ソフトウェア実行状態を記録
    ├── settings.json        # ユーザー設定を保存
    └──  cookies.txt         # 動画プラットフォームのcookie情報
└── VideoCaptioner.exe       # メインプログラム実行ファイル
```

## 📝 説明

1. 字幕の分割品質は視聴体験に重要な影響を与えます。そのため、[SubtitleSpliter](https://github.com/WEIFENG2333/SubtitleSpliter)を開発しました。これにより、単語レベルの字幕を自然言語習慣に合わせた段落に再構成し、動画画面と完璧に同期させることができます。

2. 処理過程では、純粋なテキストコンテンツのみを大規模言語モデルに送信し、タイムライン情報は含めないため、処理コストを大幅に削減できます。

3. 翻訳段階では、アンドリュー・ンによって提案された「翻訳-反省-翻訳」方法論を採用しています。この反復的な最適化方式により、翻訳の正確性を確保しています。

## 🤝 貢献ガイド

作者は大学3年生で、個人の能力とプロジェクトにはまだ多くの改善の余地があります。プロジェクトは継続的に改善中で、使用中にバグに遭遇した場合は、[Issue](https://github.com/WEIFENG2333/VideoCaptioner/issues)の提出とPull Requestによるプロジェクト改善へのご協力をお願いします。

## 更新ログ

<details>
<summary>2024.12.07</summary>

- Faster-whisper対応を追加、音声から字幕への変換品質向上
- Vad音声区切り検出対応、幻聴現象を大幅に削減
- 音声分離対応、動画のバックグラウンドノイズを分離
- 動画合成の無効化に対応
- 字幕最大長設定を追加
- 字幕末尾の句読点削除設定を追加
- 最適化と翻訳のプロンプトを改善
- LLMの字幕分割エラーを改善
- 音声変換フォーマットの不一致問題を修正

</details>

<details>
<summary>2024.11.23</summary>

- Whisper-v3モデル対応を追加、音声認識精度を大幅に向上
- 字幕分割アルゴリズムを最適化、より自然な読書体験を提供
- モデル利用可能性チェック時の安定性問題を修正
</details>

<details>
<summary>2024.11.20</summary>

- 字幕位置とスタイルのカスタマイズに対応
- 字幕最適化と翻訳プロセスのリアルタイムログ表示を追加
- API使用時の自動翻訳問題を修正
- 動画作業ディレクトリ構造を最適化、ファイル管理効率を向上
</details>

<details>
<summary>2024.11.17</summary>

- バイリンガル/モノリンガル字幕の柔軟なエクスポートに対応
- 原稿マッチングプロンプト整列機能を追加
- 字幕インポート時の安定性問題を修正
- 非中国語パスでのモデルダウンロードの互換性問題を修正
</details>

<details>
<summary>2024.11.13</summary>

- Whisper API呼び出し対応を追加
- cookie.txtのインポートで各種動画プラットフォームのリソースダウンロードに対応
- 字幕ファイル名を動画と自動的に一致
- ソフトウェアメインページにランタイムログのリアルタイム表示を追加
- ソフトウェア内部機能を統一化し完備
</details>

## ⭐ Star History

[![Star History Chart](https://api.star-history.com/svg?repos=WEIFENG2333/VideoCaptioner&type=Date)](https://star-history.com/#WEIFENG2333/VideoCaptioner&Date)

## 💖 作者を支援する

このプロジェクトがお役に立てましたら、Starを付けていただけると幸いです。それが私にとって最大の励みとサポートになります！

<div align="center">
  <img src="./docs/images/alipay.jpg" alt="Alipayコード" width="30%">
  <img src="./docs/images/wechat.jpg" alt="WeChatコード" width="30%">
</div>